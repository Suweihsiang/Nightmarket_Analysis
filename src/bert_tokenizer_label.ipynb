{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8621fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal = pd.read_csv(\"../output/normal/normal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393c901a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water = pd.read_csv(\"../output/water_army/water_army.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cda396",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_army = df_water[\"留言內容\"].tolist()\n",
    "water_army"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0749ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b1338",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e64427",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e20ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "model = BertModel.from_pretrained(\"bert-base-chinese\")\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fbe94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca57765",
   "metadata": {},
   "outputs": [],
   "source": [
    "water_army_lte_128, water_army_gt_128_lte_256, water_army_gt_256 = [], [], []\n",
    "for water in water_army:\n",
    "    if len(water) <= 128:\n",
    "        water_army_lte_128.append(water)\n",
    "    elif len(water) <= 256:\n",
    "        water_army_gt_128_lte_256.append(water)\n",
    "    else:\n",
    "        water_army_gt_256.append(water)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c598487",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in tqdm(water_army_lte_128):\n",
    "    inputs = tokenizer(\n",
    "        text, padding=\"longest\", truncation=True, return_tensors=\"pt\", max_length=128\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "\n",
    "    record = {\"text\": text}\n",
    "\n",
    "    for i, val in enumerate(cls_embedding):\n",
    "        record[f\"v{i}\"] = val\n",
    "\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c98ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in tqdm(water_army_gt_128_lte_256):\n",
    "    inputs = tokenizer(\n",
    "        text, padding=\"longest\", truncation=True, return_tensors=\"pt\", max_length=256\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "\n",
    "    record = {\"text\": text}\n",
    "\n",
    "    for i, val in enumerate(cls_embedding):\n",
    "        record[f\"v{i}\"] = val\n",
    "\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29011c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in tqdm(water_army_gt_256):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=512,\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "    inputs = {\n",
    "        k: v.to(device)\n",
    "        for k, v in inputs.items()\n",
    "        if k in [\"input_ids\", \"attention_mask\"]\n",
    "    }\n",
    "\n",
    "    cls_embeddings = []\n",
    "\n",
    "    for i in range(inputs[\"input_ids\"].shape[0]):\n",
    "        input_ids = inputs[\"input_ids\"][i].unsqueeze(0)\n",
    "        attention_mask = inputs[\"attention_mask\"][i].unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            cls_vec = outputs.last_hidden_state[:, 0, :]\n",
    "            cls_embeddings.append(cls_vec.squeeze().cpu().numpy())\n",
    "\n",
    "    final_embedding = np.mean(cls_embeddings, axis=0)\n",
    "\n",
    "    record = {\"text\": text}\n",
    "    for i, val in enumerate(final_embedding):\n",
    "        record[f\"v{i}\"] = val\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4875c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water = pd.DataFrame(records)\n",
    "df_water.to_parquet(\"../output/water_army/water_army.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65282fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = df_normal[\"留言內容\"].tolist()\n",
    "normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e240902",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_lte_128, normal_gt_128_lte_256, normal_gt_256 = [], [], []\n",
    "for norm in normal:\n",
    "    if len(norm) <= 128:\n",
    "        normal_lte_128.append(norm)\n",
    "    elif len(norm) <= 256:\n",
    "        normal_gt_128_lte_256.append(norm)\n",
    "    else:\n",
    "        normal_gt_256.append(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b64c99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_token = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902737dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in tqdm(normal_lte_128):\n",
    "    inputs = tokenizer(\n",
    "        text, padding=\"longest\", truncation=True, return_tensors=\"pt\", max_length=128\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "\n",
    "    record = {\"text\": text}\n",
    "\n",
    "    for i, val in enumerate(cls_embedding):\n",
    "        record[f\"v{i}\"] = val\n",
    "\n",
    "    normal_token.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33901420",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in tqdm(normal_gt_128_lte_256):\n",
    "    inputs = tokenizer(\n",
    "        text, padding=\"longest\", truncation=True, return_tensors=\"pt\", max_length=256\n",
    "    )\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()\n",
    "\n",
    "    record = {\"text\": text}\n",
    "\n",
    "    for i, val in enumerate(cls_embedding):\n",
    "        record[f\"v{i}\"] = val\n",
    "\n",
    "    normal_token.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c2a56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in tqdm(normal_gt_256):\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding=\"longest\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=512,\n",
    "        stride=128,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_attention_mask=True,\n",
    "    )\n",
    "    inputs = {\n",
    "        k: v.to(device)\n",
    "        for k, v in inputs.items()\n",
    "        if k in [\"input_ids\", \"attention_mask\"]\n",
    "    }\n",
    "\n",
    "    cls_embeddings = []\n",
    "\n",
    "    for i in range(inputs[\"input_ids\"].shape[0]):\n",
    "        input_ids = inputs[\"input_ids\"][i].unsqueeze(0)\n",
    "        attention_mask = inputs[\"attention_mask\"][i].unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            cls_vec = outputs.last_hidden_state[:, 0, :]\n",
    "            cls_embeddings.append(cls_vec.squeeze().cpu().numpy())\n",
    "\n",
    "    final_embedding = np.mean(cls_embeddings, axis=0)\n",
    "\n",
    "    record = {\"text\": text}\n",
    "    for i, val in enumerate(final_embedding):\n",
    "        record[f\"v{i}\"] = val\n",
    "    normal_token.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88198193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = pd.DataFrame(normal_token)\n",
    "df_norm.to_parquet(\"../output/normal/normal_comment.parquet\", engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fcfc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../output/test/raw_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a1a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = df[\"content_clean\"].tolist()\n",
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36205b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_lte_128, comments_gt_128_lte_256, comments_gt_256 = [], [], []\n",
    "for comment in comments:\n",
    "    if pd.isna(comment):\n",
    "        pass\n",
    "    elif len(comment) <= 128:\n",
    "        comments_lte_128.append(comment)\n",
    "    elif len(comment) <= 256:\n",
    "        comments_gt_128_lte_256.append(comment)\n",
    "    else:\n",
    "        comments_gt_256.append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81643d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "for i in range(0, len(comments_lte_128), batch_size):\n",
    "    batch_end = min(i + batch_size, len(comments_lte_128))\n",
    "    batch = comments_lte_128[i:batch_end]\n",
    "    batch_records = []\n",
    "\n",
    "    for text in tqdm(batch, desc=f\"Batch {i // batch_size + 1}\"):\n",
    "        try:\n",
    "            inputs = tokenizer(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "                max_length=128,\n",
    "            )\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                cls_embedding = outputs.last_hidden_state[0, 0, :].cpu().numpy()\n",
    "\n",
    "            record = {\"text\": text}\n",
    "            for j, val in enumerate(cls_embedding):\n",
    "                record[f\"v{j}\"] = val\n",
    "            batch_records.append(record)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on text: {text[:30]} — {e}\")\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame(batch_records)\n",
    "    df.to_parquet(f\"../output/test/comment_lte128_part_{i // batch_size + 1}.parquet\")\n",
    "\n",
    "    del batch_records\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf56a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "for i in range(0, len(comments_gt_128_lte_256), batch_size):\n",
    "    batch_end = min(i + batch_size, len(comments_gt_128_lte_256))\n",
    "    batch = comments_gt_128_lte_256[i:batch_end]\n",
    "    batch_records = []\n",
    "\n",
    "    for text in tqdm(batch, desc=f\"Batch {i // batch_size + 1}\"):\n",
    "        try:\n",
    "            inputs = tokenizer(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "                max_length=256,\n",
    "            )\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                cls_embedding = outputs.last_hidden_state[0, 0, :].cpu().numpy()\n",
    "\n",
    "            record = {\"text\": text}\n",
    "            for j, val in enumerate(cls_embedding):\n",
    "                record[f\"v{j}\"] = val\n",
    "            batch_records.append(record)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on text: {text[:30]} — {e}\")\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame(batch_records)\n",
    "    df.to_parquet(\n",
    "        f\"../output/test/comment_gt128_lte256_part_{i // batch_size + 1}.parquet\"\n",
    "    )\n",
    "\n",
    "    del batch_records\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07639dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "for i in range(0, len(comments_gt_256), batch_size):\n",
    "    batch_end = min(i + batch_size, len(comments_gt_256))\n",
    "    batch = comments_gt_256[i:batch_end]\n",
    "    batch_records = []\n",
    "\n",
    "    for text in tqdm(batch, desc=f\"Batch {i // batch_size + 1}\"):\n",
    "        try:\n",
    "            inputs = tokenizer(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "                max_length=512,\n",
    "                stride=128,\n",
    "                return_overflowing_tokens=True,\n",
    "                return_attention_mask=True,\n",
    "            )\n",
    "            inputs = {\n",
    "                k: v.to(device)\n",
    "                for k, v in inputs.items()\n",
    "                if k in [\"input_ids\", \"attention_mask\"]\n",
    "            }\n",
    "\n",
    "            cls_embeddings = []\n",
    "            for chunk_idx in range(inputs[\"input_ids\"].shape[0]):\n",
    "                input_ids = inputs[\"input_ids\"][chunk_idx].unsqueeze(0)\n",
    "                attention_mask = inputs[\"attention_mask\"][chunk_idx].unsqueeze(0)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    cls_vec = outputs.last_hidden_state[:, 0, :]\n",
    "                    cls_embeddings.append(cls_vec.squeeze().cpu().numpy())\n",
    "\n",
    "            final_embedding = np.mean(cls_embeddings, axis=0)\n",
    "\n",
    "            record = {\"text\": text}\n",
    "            for j, val in enumerate(final_embedding):\n",
    "                record[f\"v{j}\"] = val\n",
    "\n",
    "            batch_records.append(record)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on text: {text[:30]}... => {e}\")\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame(batch_records)\n",
    "    df.to_parquet(f\"../output/test/comment_gte256_part_{i // batch_size + 1}.parquet\")\n",
    "\n",
    "    del batch_records\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
