{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d41072-a2e2-4add-9ff3-08cd6789a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "613bc06b-b8e8-4220-9c32-56cd785b3fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency\n",
      "org.apache.spark#spark-avro_2.12 added as a dependency\n",
      "org.elasticsearch#elasticsearch-spark-30_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-a59127d2-0602-4128-aba1-2e99944ab3d6;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 in central\n",
      "\tfound org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 in central\n",
      "\tfound org.apache.kafka#kafka-clients;3.4.1 in central\n",
      "\tfound org.lz4#lz4-java;1.8.0 in central\n",
      "\tfound org.xerial.snappy#snappy-java;1.1.10.3 in central\n",
      "\tfound org.slf4j#slf4j-api;2.0.7 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-runtime;3.3.4 in central\n",
      "\tfound org.apache.hadoop#hadoop-client-api;3.3.4 in central\n",
      "\tfound commons-logging#commons-logging;1.1.3 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.0 in central\n",
      "\tfound org.apache.commons#commons-pool2;2.11.1 in central\n",
      "\tfound org.apache.spark#spark-avro_2.12;3.5.0 in central\n",
      "\tfound org.tukaani#xz;1.9 in central\n",
      "\tfound org.elasticsearch#elasticsearch-spark-30_2.12;8.12.2 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.8 in central\n",
      "\tfound javax.xml.bind#jaxb-api;2.3.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java;2.5.0 in central\n",
      "\tfound org.apache.spark#spark-yarn_2.12;3.3.3 in central\n",
      ":: resolution report :: resolve 227ms :: artifacts dl 8ms\n",
      "\t:: modules in use:\n",
      "\tcom.google.code.findbugs#jsr305;3.0.0 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;2.5.0 from central in [default]\n",
      "\tcommons-logging#commons-logging;1.1.3 from central in [default]\n",
      "\tjavax.xml.bind#jaxb-api;2.3.1 from central in [default]\n",
      "\torg.apache.commons#commons-pool2;2.11.1 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-api;3.3.4 from central in [default]\n",
      "\torg.apache.hadoop#hadoop-client-runtime;3.3.4 from central in [default]\n",
      "\torg.apache.kafka#kafka-clients;3.4.1 from central in [default]\n",
      "\torg.apache.spark#spark-avro_2.12;3.5.0 from central in [default]\n",
      "\torg.apache.spark#spark-sql-kafka-0-10_2.12;3.5.0 from central in [default]\n",
      "\torg.apache.spark#spark-token-provider-kafka-0-10_2.12;3.5.0 from central in [default]\n",
      "\torg.apache.spark#spark-yarn_2.12;3.3.3 from central in [default]\n",
      "\torg.elasticsearch#elasticsearch-spark-30_2.12;8.12.2 from central in [default]\n",
      "\torg.lz4#lz4-java;1.8.0 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.8 from central in [default]\n",
      "\torg.slf4j#slf4j-api;2.0.7 from central in [default]\n",
      "\torg.tukaani#xz;1.9 from central in [default]\n",
      "\torg.xerial.snappy#snappy-java;1.1.10.3 from central in [default]\n",
      "\t:: evicted modules:\n",
      "\torg.slf4j#slf4j-api;1.7.6 by [org.slf4j#slf4j-api;2.0.7] in [default]\n",
      "\tcommons-logging#commons-logging;1.1.1 by [commons-logging#commons-logging;1.1.3] in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   20  |   0   |   0   |   2   ||   18  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-a59127d2-0602-4128-aba1-2e99944ab3d6\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 18 already retrieved (0kB/7ms)\n",
      "25/06/17 16:29:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"ModelTrain\").master(\"local[*]\").getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7987794a-4cd7-4b5c-a173-f1d95842227a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_water = spark.read.parquet(\"hdfs://namenode:9000/workspace/output/water_army/water_army_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57efa381-6844-4843-8aa2-a7213e85161c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal = spark.read.parquet(\"hdfs://namenode:9000/workspace/output/normal/normal_comment_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f1a88ce-d1ad-45c4-b681-9a45f96bb99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_label = df_water.unionByName(df_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8ddb281-fd8f-45c3-95d2-3297863239b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[text: string, v0: float, v1: float, v2: float, v3: float, v4: float, v5: float, v6: float, v7: float, v8: float, v9: float, v10: float, v11: float, v12: float, v13: float, v14: float, v15: float, v16: float, v17: float, v18: float, v19: float, v20: float, v21: float, v22: float, v23: float, v24: float, v25: float, v26: float, v27: float, v28: float, v29: float, v30: float, v31: float, v32: float, v33: float, v34: float, v35: float, v36: float, v37: float, v38: float, v39: float, v40: float, v41: float, v42: float, v43: float, v44: float, v45: float, v46: float, v47: float, v48: float, v49: float, v50: float, v51: float, v52: float, v53: float, v54: float, v55: float, v56: float, v57: float, v58: float, v59: float, v60: float, v61: float, v62: float, v63: float, v64: float, v65: float, v66: float, v67: float, v68: float, v69: float, v70: float, v71: float, v72: float, v73: float, v74: float, v75: float, v76: float, v77: float, v78: float, v79: float, v80: float, v81: float, v82: float, v83: float, v84: float, v85: float, v86: float, v87: float, v88: float, v89: float, v90: float, v91: float, v92: float, v93: float, v94: float, v95: float, v96: float, v97: float, v98: float, v99: float, v100: float, v101: float, v102: float, v103: float, v104: float, v105: float, v106: float, v107: float, v108: float, v109: float, v110: float, v111: float, v112: float, v113: float, v114: float, v115: float, v116: float, v117: float, v118: float, v119: float, v120: float, v121: float, v122: float, v123: float, v124: float, v125: float, v126: float, v127: float, v128: float, v129: float, v130: float, v131: float, v132: float, v133: float, v134: float, v135: float, v136: float, v137: float, v138: float, v139: float, v140: float, v141: float, v142: float, v143: float, v144: float, v145: float, v146: float, v147: float, v148: float, v149: float, v150: float, v151: float, v152: float, v153: float, v154: float, v155: float, v156: float, v157: float, v158: float, v159: float, v160: float, v161: float, v162: float, v163: float, v164: float, v165: float, v166: float, v167: float, v168: float, v169: float, v170: float, v171: float, v172: float, v173: float, v174: float, v175: float, v176: float, v177: float, v178: float, v179: float, v180: float, v181: float, v182: float, v183: float, v184: float, v185: float, v186: float, v187: float, v188: float, v189: float, v190: float, v191: float, v192: float, v193: float, v194: float, v195: float, v196: float, v197: float, v198: float, v199: float, v200: float, v201: float, v202: float, v203: float, v204: float, v205: float, v206: float, v207: float, v208: float, v209: float, v210: float, v211: float, v212: float, v213: float, v214: float, v215: float, v216: float, v217: float, v218: float, v219: float, v220: float, v221: float, v222: float, v223: float, v224: float, v225: float, v226: float, v227: float, v228: float, v229: float, v230: float, v231: float, v232: float, v233: float, v234: float, v235: float, v236: float, v237: float, v238: float, v239: float, v240: float, v241: float, v242: float, v243: float, v244: float, v245: float, v246: float, v247: float, v248: float, v249: float, v250: float, v251: float, v252: float, v253: float, v254: float, v255: float, v256: float, v257: float, v258: float, v259: float, v260: float, v261: float, v262: float, v263: float, v264: float, v265: float, v266: float, v267: float, v268: float, v269: float, v270: float, v271: float, v272: float, v273: float, v274: float, v275: float, v276: float, v277: float, v278: float, v279: float, v280: float, v281: float, v282: float, v283: float, v284: float, v285: float, v286: float, v287: float, v288: float, v289: float, v290: float, v291: float, v292: float, v293: float, v294: float, v295: float, v296: float, v297: float, v298: float, v299: float, v300: float, v301: float, v302: float, v303: float, v304: float, v305: float, v306: float, v307: float, v308: float, v309: float, v310: float, v311: float, v312: float, v313: float, v314: float, v315: float, v316: float, v317: float, v318: float, v319: float, v320: float, v321: float, v322: float, v323: float, v324: float, v325: float, v326: float, v327: float, v328: float, v329: float, v330: float, v331: float, v332: float, v333: float, v334: float, v335: float, v336: float, v337: float, v338: float, v339: float, v340: float, v341: float, v342: float, v343: float, v344: float, v345: float, v346: float, v347: float, v348: float, v349: float, v350: float, v351: float, v352: float, v353: float, v354: float, v355: float, v356: float, v357: float, v358: float, v359: float, v360: float, v361: float, v362: float, v363: float, v364: float, v365: float, v366: float, v367: float, v368: float, v369: float, v370: float, v371: float, v372: float, v373: float, v374: float, v375: float, v376: float, v377: float, v378: float, v379: float, v380: float, v381: float, v382: float, v383: float, v384: float, v385: float, v386: float, v387: float, v388: float, v389: float, v390: float, v391: float, v392: float, v393: float, v394: float, v395: float, v396: float, v397: float, v398: float, v399: float, v400: float, v401: float, v402: float, v403: float, v404: float, v405: float, v406: float, v407: float, v408: float, v409: float, v410: float, v411: float, v412: float, v413: float, v414: float, v415: float, v416: float, v417: float, v418: float, v419: float, v420: float, v421: float, v422: float, v423: float, v424: float, v425: float, v426: float, v427: float, v428: float, v429: float, v430: float, v431: float, v432: float, v433: float, v434: float, v435: float, v436: float, v437: float, v438: float, v439: float, v440: float, v441: float, v442: float, v443: float, v444: float, v445: float, v446: float, v447: float, v448: float, v449: float, v450: float, v451: float, v452: float, v453: float, v454: float, v455: float, v456: float, v457: float, v458: float, v459: float, v460: float, v461: float, v462: float, v463: float, v464: float, v465: float, v466: float, v467: float, v468: float, v469: float, v470: float, v471: float, v472: float, v473: float, v474: float, v475: float, v476: float, v477: float, v478: float, v479: float, v480: float, v481: float, v482: float, v483: float, v484: float, v485: float, v486: float, v487: float, v488: float, v489: float, v490: float, v491: float, v492: float, v493: float, v494: float, v495: float, v496: float, v497: float, v498: float, v499: float, v500: float, v501: float, v502: float, v503: float, v504: float, v505: float, v506: float, v507: float, v508: float, v509: float, v510: float, v511: float, v512: float, v513: float, v514: float, v515: float, v516: float, v517: float, v518: float, v519: float, v520: float, v521: float, v522: float, v523: float, v524: float, v525: float, v526: float, v527: float, v528: float, v529: float, v530: float, v531: float, v532: float, v533: float, v534: float, v535: float, v536: float, v537: float, v538: float, v539: float, v540: float, v541: float, v542: float, v543: float, v544: float, v545: float, v546: float, v547: float, v548: float, v549: float, v550: float, v551: float, v552: float, v553: float, v554: float, v555: float, v556: float, v557: float, v558: float, v559: float, v560: float, v561: float, v562: float, v563: float, v564: float, v565: float, v566: float, v567: float, v568: float, v569: float, v570: float, v571: float, v572: float, v573: float, v574: float, v575: float, v576: float, v577: float, v578: float, v579: float, v580: float, v581: float, v582: float, v583: float, v584: float, v585: float, v586: float, v587: float, v588: float, v589: float, v590: float, v591: float, v592: float, v593: float, v594: float, v595: float, v596: float, v597: float, v598: float, v599: float, v600: float, v601: float, v602: float, v603: float, v604: float, v605: float, v606: float, v607: float, v608: float, v609: float, v610: float, v611: float, v612: float, v613: float, v614: float, v615: float, v616: float, v617: float, v618: float, v619: float, v620: float, v621: float, v622: float, v623: float, v624: float, v625: float, v626: float, v627: float, v628: float, v629: float, v630: float, v631: float, v632: float, v633: float, v634: float, v635: float, v636: float, v637: float, v638: float, v639: float, v640: float, v641: float, v642: float, v643: float, v644: float, v645: float, v646: float, v647: float, v648: float, v649: float, v650: float, v651: float, v652: float, v653: float, v654: float, v655: float, v656: float, v657: float, v658: float, v659: float, v660: float, v661: float, v662: float, v663: float, v664: float, v665: float, v666: float, v667: float, v668: float, v669: float, v670: float, v671: float, v672: float, v673: float, v674: float, v675: float, v676: float, v677: float, v678: float, v679: float, v680: float, v681: float, v682: float, v683: float, v684: float, v685: float, v686: float, v687: float, v688: float, v689: float, v690: float, v691: float, v692: float, v693: float, v694: float, v695: float, v696: float, v697: float, v698: float, v699: float, v700: float, v701: float, v702: float, v703: float, v704: float, v705: float, v706: float, v707: float, v708: float, v709: float, v710: float, v711: float, v712: float, v713: float, v714: float, v715: float, v716: float, v717: float, v718: float, v719: float, v720: float, v721: float, v722: float, v723: float, v724: float, v725: float, v726: float, v727: float, v728: float, v729: float, v730: float, v731: float, v732: float, v733: float, v734: float, v735: float, v736: float, v737: float, v738: float, v739: float, v740: float, v741: float, v742: float, v743: float, v744: float, v745: float, v746: float, v747: float, v748: float, v749: float, v750: float, v751: float, v752: float, v753: float, v754: float, v755: float, v756: float, v757: float, v758: float, v759: float, v760: float, v761: float, v762: float, v763: float, v764: float, v765: float, v766: float, v767: float, label: int]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_label.orderBy(F.rand())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e9afa55-9428-4df4-8e6d-2bda9b0e6369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1| 1800|\n",
      "|    0| 2106|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_all_label.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fec6405-6a75-49e6-bbf3-22a35bd596f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors,VectorUDT\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5545386-0ce5-41f2-9eeb-8f516f37091f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_column = [col for col in df_all_label.columns if col.startswith(\"v\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45732e88-515f-4f71-94c3-9c2153a30a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(inputCols=vector_column,outputCol=\"features\")\n",
    "df_all_label_ready = assembler.transform(df_all_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6b24f98-3ac1-4401-b713-fbad917114b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_vector_udf = udf(lambda arr: Vectors.dense(arr), VectorUDT())\n",
    "df_all_label_ready = df_all_label_ready.withColumn(\"features\",to_vector_udf(\"features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc9517eb-aee3-4bf6-9fc2-fe81b83c752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df,test_df = df_all_label_ready.randomSplit([0.8,0.2],seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f16f9680-2517-487c-a66e-ae5c238c1cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "def evaluate_model(model, train_data, test_data):\n",
    "    train_pred = model.transform(train_data)\n",
    "    test_pred = model.transform(test_data)\n",
    "\n",
    "    binary_evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "\n",
    "    evaluator_acc = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    evaluator_precision = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"precisionByLabel\")\n",
    "    evaluator_recall = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"recallByLabel\")\n",
    "    evaluator_f1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "    def evaluate_all(pred_df, dataset_name):\n",
    "        auc = binary_evaluator.evaluate(pred_df)\n",
    "        acc = evaluator_acc.evaluate(pred_df)\n",
    "        precision = evaluator_precision.evaluate(pred_df)\n",
    "        recall = evaluator_recall.evaluate(pred_df)\n",
    "        f1 = evaluator_f1.evaluate(pred_df)\n",
    "\n",
    "        print(f\"\\n{dataset_name} Evaluation Results:\")\n",
    "        print(f\"AUC       = {auc:.4f}\")\n",
    "        print(f\"Accuracy  = {acc:.4f}\")\n",
    "        print(f\"Precision = {precision:.4f}\")\n",
    "        print(f\"Recall    = {recall:.4f}\")\n",
    "        print(f\"F1-score  = {f1:.4f}\")\n",
    "        return auc, acc, precision, recall, f1\n",
    "\n",
    "    auc_train, acc_train, p_train, r_train, f_train = evaluate_all(train_pred, \"Train Set\")\n",
    "\n",
    "    auc_test, acc_test, p_test, r_test, f_test = evaluate_all(test_pred, \"Test Set\")\n",
    "\n",
    "    print(\"\\nSummary:\")\n",
    "    auc_gap = abs(auc_train - auc_test)\n",
    "    acc_gap = abs(acc_train - acc_test)\n",
    "    f1_gap = abs(f_train - f_test)\n",
    "\n",
    "    if auc_gap > 0.05 or acc_gap > 0.05:\n",
    "        print(\"The model may be overfitting: significant performance drop on test set.\")\n",
    "    elif auc_test < 0.8 or f_test < 0.75:\n",
    "        print(\"Test performance is suboptimal. The model may lack generalization.\")\n",
    "    else:\n",
    "        print(\"The model shows consistent train-test performance and good generalization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "144e03e5-bccb-40bb-ba13-be8b12b84133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Set Evaluation Results:\n",
      "AUC       = 0.9969\n",
      "Accuracy  = 0.9804\n",
      "Precision = 0.9787\n",
      "Recall    = 0.9845\n",
      "F1-score  = 0.9804\n",
      "\n",
      "Test Set Evaluation Results:\n",
      "AUC       = 0.9831\n",
      "Accuracy  = 0.9390\n",
      "Precision = 0.9423\n",
      "Recall    = 0.9533\n",
      "F1-score  = 0.9390\n",
      "\n",
      "Summary:\n",
      "The model shows consistent train-test performance and good generalization.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import CrossValidator,ParamGridBuilder\n",
    "lr = LogisticRegression(featuresCol=\"features\",labelCol=\"label\")\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam,[0.0,0.1,0.01])\n",
    "             .addGrid(lr.elasticNetParam,[0.0,0.5,1.0])\n",
    "             .build())\n",
    "evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\")\n",
    "cv = CrossValidator(estimator=lr,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=5)\n",
    "cv_model = cv.fit(train_df)\n",
    "evaluate_model(cv_model, train_df, test_df)\n",
    "cv_model.write().overwrite().save(\"hdfs://namenode:9000/workspace/output/model/lr_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50635740-2eac-4ea7-ab66-f2b208c1627c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Set Evaluation Results:\n",
      "AUC       = 0.9995\n",
      "Accuracy  = 0.9949\n",
      "Precision = 0.9929\n",
      "Recall    = 0.9976\n",
      "F1-score  = 0.9949\n",
      "\n",
      "Test Set Evaluation Results:\n",
      "AUC       = 0.9465\n",
      "Accuracy  = 0.8672\n",
      "Precision = 0.8650\n",
      "Recall    = 0.9136\n",
      "F1-score  = 0.8663\n",
      "\n",
      "Summary:\n",
      "The model may be overfitting: significant performance drop on test set.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(featuresCol=\"features\",labelCol=\"label\",predictionCol=\"prediction\",probabilityCol=\"probability\",seed=42)\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(rf.numTrees,[20,50])\n",
    "             .addGrid(rf.maxDepth,[5,10])\n",
    "             .build())\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\",rawPredictionCol=\"rawPrediction\",metricName=\"areaUnderROC\")\n",
    "cv = CrossValidator(estimator=rf,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=3,\n",
    "                    parallelism=2)\n",
    "cv_model = cv.fit(train_df)\n",
    "evaluate_model(cv_model, train_df, test_df)\n",
    "cv_model.write().overwrite().save(\"hdfs://namenode:9000/workspace/output/model/rf_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cf33838-7aa7-4397-8a09-09795ce76c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Set Evaluation Results:\n",
      "AUC       = 0.9908\n",
      "Accuracy  = 0.9634\n",
      "Precision = 0.9567\n",
      "Recall    = 0.9750\n",
      "F1-score  = 0.9634\n",
      "\n",
      "Test Set Evaluation Results:\n",
      "AUC       = 0.9814\n",
      "Accuracy  = 0.9350\n",
      "Precision = 0.9299\n",
      "Recall    = 0.9603\n",
      "F1-score  = 0.9347\n",
      "\n",
      "Summary:\n",
      "The model shows consistent train-test performance and good generalization.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "svm = LinearSVC(featuresCol='features', labelCol='label', maxIter=100)\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(svm.regParam,[0.0,0.1,1.0])\n",
    "             .build())\n",
    "evaluator = BinaryClassificationEvaluator(metricName=\"areaUnderROC\",labelCol=\"label\")\n",
    "cv = CrossValidator(estimator=svm,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=5)\n",
    "cv_model = cv.fit(train_df)\n",
    "evaluate_model(cv_model, train_df, test_df)\n",
    "cv_model.write().overwrite().save(\"hdfs://namenode:9000/workspace/output/model/svm_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61d17419-3861-416c-9b0e-10002ba09c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Set Evaluation Results:\n",
      "AUC       = 0.9997\n",
      "Accuracy  = 0.9975\n",
      "Precision = 0.9970\n",
      "Recall    = 0.9982\n",
      "F1-score  = 0.9975\n",
      "\n",
      "Test Set Evaluation Results:\n",
      "AUC       = 0.9523\n",
      "Accuracy  = 0.8821\n",
      "Precision = 0.8920\n",
      "Recall    = 0.9065\n",
      "F1-score  = 0.8819\n",
      "\n",
      "Summary:\n",
      "The model may be overfitting: significant performance drop on test set.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(gbt.maxIter, [50, 100])\n",
    "             .addGrid(gbt.maxDepth, [3, 5])\n",
    "             .addGrid(gbt.stepSize, [0.1, 0.2])\n",
    "             .build())\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", metricName=\"areaUnderROC\")\n",
    "cv = CrossValidator(estimator=gbt,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3,\n",
    "                          parallelism=2)\n",
    "cv_model = cv.fit(train_df)\n",
    "evaluate_model(cv_model, train_df, test_df)\n",
    "cv_model.write().overwrite().save(\"hdfs://namenode:9000/workspace/output/model/gbt_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae34cbf1-16de-4fb2-ab5a-8fd533badbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
