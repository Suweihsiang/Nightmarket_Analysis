{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8621fdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da683f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../output/comments/comments_Cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0749ab63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b1338",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e64427",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e20ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "model = BertModel.from_pretrained(\"bert-base-chinese\")\n",
    "model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a1a144",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = df[\"content_clean\"].tolist()\n",
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36205b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_lte_128, comments_gt_128_lte_256, comments_gt_256 = [], [], []\n",
    "for comment in comments:\n",
    "    if pd.isna(comment):\n",
    "        pass\n",
    "    elif len(comment) <= 128:\n",
    "        comments_lte_128.append(comment)\n",
    "    elif len(comment) <= 256:\n",
    "        comments_gt_128_lte_256.append(comment)\n",
    "    else:\n",
    "        comments_gt_256.append(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81643d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "for i in range(0, len(comments_lte_128), batch_size):\n",
    "    batch_end = min(i + batch_size, len(comments_lte_128))\n",
    "    batch = comments_lte_128[i:batch_end]\n",
    "    batch_records = []\n",
    "\n",
    "    for text in tqdm(batch, desc=f\"Batch {i // batch_size + 1}\"):\n",
    "        try:\n",
    "            inputs = tokenizer(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "                max_length=128,\n",
    "            )\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                cls_embedding = outputs.last_hidden_state[0, 0, :].cpu().numpy()\n",
    "\n",
    "            record = {\"text\": text}\n",
    "            for j, val in enumerate(cls_embedding):\n",
    "                record[f\"v{j}\"] = val\n",
    "            batch_records.append(record)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on text: {text[:30]} — {e}\")\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame(batch_records)\n",
    "    df.to_parquet(f\"../output/comments/comment_lte128_part_{i // batch_size + 1}.parquet\")\n",
    "\n",
    "    del batch_records\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf56a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "for i in range(0, len(comments_gt_128_lte_256), batch_size):\n",
    "    batch_end = min(i + batch_size, len(comments_gt_128_lte_256))\n",
    "    batch = comments_gt_128_lte_256[i:batch_end]\n",
    "    batch_records = []\n",
    "\n",
    "    for text in tqdm(batch, desc=f\"Batch {i // batch_size + 1}\"):\n",
    "        try:\n",
    "            inputs = tokenizer(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "                max_length=256,\n",
    "            )\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**inputs)\n",
    "                cls_embedding = outputs.last_hidden_state[0, 0, :].cpu().numpy()\n",
    "\n",
    "            record = {\"text\": text}\n",
    "            for j, val in enumerate(cls_embedding):\n",
    "                record[f\"v{j}\"] = val\n",
    "            batch_records.append(record)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on text: {text[:30]} — {e}\")\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame(batch_records)\n",
    "    df.to_parquet(f\"../output/comments/comment_gt128_lte256_part_{i // batch_size + 1}.parquet\")\n",
    "\n",
    "    del batch_records\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07639dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "for i in range(0, len(comments_gt_256), batch_size):\n",
    "    batch_end = min(i + batch_size, len(comments_gt_256))\n",
    "    batch = comments_gt_256[i:batch_end]\n",
    "    batch_records = []\n",
    "\n",
    "    for text in tqdm(batch, desc=f\"Batch {i // batch_size + 1}\"):\n",
    "        try:\n",
    "            inputs = tokenizer(\n",
    "                text,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\",\n",
    "                max_length=512,\n",
    "                stride=128,\n",
    "                return_overflowing_tokens=True,\n",
    "                return_attention_mask=True,\n",
    "            )\n",
    "            inputs = {\n",
    "                k: v.to(device)\n",
    "                for k, v in inputs.items()\n",
    "                if k in [\"input_ids\", \"attention_mask\"]\n",
    "            }\n",
    "\n",
    "            cls_embeddings = []\n",
    "            for chunk_idx in range(inputs[\"input_ids\"].shape[0]):\n",
    "                input_ids = inputs[\"input_ids\"][chunk_idx].unsqueeze(0)\n",
    "                attention_mask = inputs[\"attention_mask\"][chunk_idx].unsqueeze(0)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    cls_vec = outputs.last_hidden_state[:, 0, :]\n",
    "                    cls_embeddings.append(cls_vec.squeeze().cpu().numpy())\n",
    "\n",
    "            final_embedding = np.mean(cls_embeddings, axis=0)\n",
    "\n",
    "            record = {\"text\": text}\n",
    "            for j, val in enumerate(final_embedding):\n",
    "                record[f\"v{j}\"] = val\n",
    "\n",
    "            batch_records.append(record)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on text: {text[:30]}... => {e}\")\n",
    "            continue\n",
    "\n",
    "    df = pd.DataFrame(batch_records)\n",
    "    df.to_parquet(f\"../output/comments/comment_gte256_part_{i // batch_size + 1}.parquet\")\n",
    "\n",
    "    del batch_records\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
